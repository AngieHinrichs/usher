'''
This is a simple snakemake workflow for running usher, matUtils, and ripples

Include in the current working direcotry:
    1. a fasta file with SARS-CoV-2 genome sequences: [user_fa] (below)
    2. the Snakefile
    3. the environment file, usher.yaml

Users can run each workflow as:

UShER: add samples to the latest public MAT
    snakemake --use-conda --cores [num threads] --config FASTA="[user_fa]" RUNTYPE="usher"
matUtils: extract subtrees in auspice.us compatible json format using matUtils
    snakemake --use-conda --cores [num threads] --config FASTA="[user_fa]" RUNTYPE="matUtils"
ripples: detect recombinants in the ancestry of the user-supplied samples
    snakemake --use-conda --cores [num threads] --config FASTA="[user_fa]" RUNTYPE="ripples"
translate: translate all mutations to AA affecting sites
    snakemake --use-conda --cores [num threads] --config FASTA="[user_fa]" RUNTYPE="translate"
taxodium: output taxodium format protobuf for visualization of the big tree
    snakemake --use-conda --cores [num threads] --config FASTA="[user_fa]" RUNTYPE="taxodium"
introduce: run introduce on the user provided samples to identify clusters
    snakemake --use-conda --cores [num threads] --config FASTA="[user_fa]" RUNTYPE="introduce"

For each run type, the usher.yaml environment file must be present in the working directory.

There are many other advanced options, for more information, please see the wiki:

    https://usher-wiki.readthedocs.io/en/latest/

rucorbet@ucsc.educ


'''

rule all:
    input:
        config["RUNTYPE"]

rule download_reference:
    output:
        "wuhCor1.fa"
    conda:
        "usher.yaml"
    shell:
        "wget https://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/bigZips/wuhCor1.fa.gz && gunzip wuhCor1.fa.gz"

rule align_seqs :
    input:
        "wuhCor1.fa",
        config["FASTA"]
    output:
        "aligned_seqs.fa"
    conda:
        "usher.yaml"
    threads:
        64
    shell:
        "mafft --thread {threads} --auto --keeplength --addfragments {input[1]} wuhCor1.fa > aligned_seqs.fa"

rule download_masking :
    output:
        "problematic_sites_sarsCov2.vcf"
    conda:
        "usher.yaml"
    shell:
        "wget https://raw.githubusercontent.com/W-L/ProblematicSites_SARS-CoV2/master/problematic_sites_sarsCov2.vcf"

rule create_vcf :
    input:
         "aligned_seqs.fa",
         "problematic_sites_sarsCov2.vcf"
    output:
         "aligned_seqs.vcf"
    conda:
         "usher.yaml"
    shell:
         "faToVcf -maskSites=problematic_sites_sarsCov2.vcf aligned_seqs.fa aligned_seqs.vcf"

rule download_protobuf :
    output:
        "public-latest.all.masked.pb.gz"
    conda:
        "usher.yaml"
    shell:
        "wget http://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/UShER_SARS-CoV-2/public-latest.all.masked.pb.gz"

rule usher :
    input:
        "public-latest.all.masked.pb.gz",
        "aligned_seqs.vcf"
    conda:
        "usher.yaml"
    output:
        "user_seqs.pb",
        temp("usher"),
        "final-tree.nh",
        "mutation-paths.txt"
    threads:
        64
    shell:
        "usher -T {threads} -i public-latest.all.masked.pb.gz -v aligned_seqs.vcf -o user_seqs.pb > usher"

rule introduce :
    input:
        "user_seqs.pb",
        "user_samples.txt"
    conda:
        "usher.yaml"
    output:
        temp("introduce"),
        "user_seqs.introductions.txt",
        "user_seqs.clusters.txt"
    threads:
        64
    shell:
        "matUtils introduce -T {threads} -i user_seqs.pb -s user_samples.txt -u user_seqs.clusters.txt -o user_seqs.introductions.txt > introduce"
        
rule get_sample_ids :
    input:
        config["FASTA"]
    conda:
        "usher.yaml"
    output:
        "user_samples.txt"
    shell:
        "grep -e '>' {input[0]} | perl -pi -e 's/>//' > user_samples.txt"

rule download_metadata :
    conda:
        "usher.yaml"
    output:
        "public-latest.metadata.tsv"
    shell:
        "wget http://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/UShER_SARS-CoV-2/public-latest.metadata.tsv.gz && gunzip public-latest.metadata.tsv.gz"

rule download_gtf :
    conda:
        "usher.yaml"
    output:
        "ncbiGenes.gtf"
    shell:
        "wget http://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/bigZips/genes/ncbiGenes.gtf.gz && gunzip ncbiGenes.gtf.gz"

rule translate :
    input:
        "ncbiGenes.gtf",
        "user_seqs.pb",
        "wuhCor1.fa"
    conda:
        "usher.yaml"
    threads:
        64
    output:
        "user_seqs.translation.tsv",
        temp("translate")
    shell:
        "matUtils summary -t {output[0]} -i {input[1]} -g {input[0]} -f {input[2]} > translate"

rule extract_subtrees :
    input :
        "public-latest.metadata.tsv",
        "user_seqs.pb",
        "user_samples.txt",
        "user_seqs.translation.tsv"
    conda:
        "usher.yaml"
    output :
        temp("matUtils"),
        "subtree-assignments.tsv"
    threads:
        64
    shell :
        "matUtils extract -T {threads} -i user_seqs.pb -s user_samples.txt -M public-latest.metadata.tsv,user_seqs.translation.tsv -N 500 -j user > matUtils"

rule taxodium :
    input :
        "user_seqs.pb",
        "ncbiGenes.gtf",
        "wuhCor1.fa",
        "public-latest.metadata.tsv"
    output:
        "user_seqs.taxodium.pb",
        temp("taxodium")
    conda:
        "usher.yaml"
    threads:
        64
    shell:
        "matUtils extract -i {input[0]} -T {threads} -l {output[0]} -g {input[1]} -f {input[2]} -M {input[3]} > taxodium"

rule ripples :
    input :
        "user_seqs.pb",
        "user_samples.txt"
    output:
        temp("ripples")
    conda:
        "usher.yaml"
    threads:
        64
    shell:
        "ripples -i user_seqs.pb -s user_samples.txt -T {threads} > ripples"
